{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f44012c4",
   "metadata": {},
   "source": [
    "# Captum: Model Interpretability for PyTorch\n",
    "\n",
    "Captum is a model interpretability library for PyTorch that provides insights into how models make predictions. It offers:\n",
    "\n",
    "- Attribution techniques to identify input feature importance\n",
    "- Tools for understanding model behavior and decision-making\n",
    "- Methods to analyze neural network internals\n",
    "- Visualization capabilities for model explanations\n",
    "- Support for both vision and text models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92ce313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import ShapleyValueSampling, LLMAttribution, TextTemplateInput, ProductBaselines, ShapleyValues, Lime, KernelShap\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902c0488",
   "metadata": {},
   "source": [
    "# Model and Tokenizer\n",
    "We selected the DistilGPT model and tokenizer from Huggingface, since it is\n",
    "- reasonably small (parameters are ca 350MB)\n",
    "- runs relatively fast, even on CPU\n",
    "- funfact: biases (e.g. gender) are more pronounced than in ChatGPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294884ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"distilbert/distilgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce6fc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilgpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3672a0",
   "metadata": {},
   "source": [
    "Wrap model in various attribution techniques.\n",
    "\n",
    "Note that the LLM Attribution does only work with `FeatureAblation`, `ShapleyValueSampling`, `ShapleyValues`, `Lime`, and `KernelShap`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edc0a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Attribution method. Select one of [svs, sv, lime, kernel]\n",
    "attr_txt = \"svs\"\n",
    "\n",
    "if attr_txt == \"svs\":\n",
    "    attr = ShapleyValueSampling(model)\n",
    "elif attr_txt == \"sv\":\n",
    "    attr = ShapleyValues(model)\n",
    "elif attr_txt == \"lime\":\n",
    "    attr = Lime(model)\n",
    "elif attr_txt == \"kernel\":\n",
    "    attr = KernelShap(model)\n",
    "else:\n",
    "    raise ValueError(f\"attr_txt should be one of [svs, sv, lime, kernel], got {attr_txt} instead\")\n",
    "\n",
    "# Instantiate the Attribution wrapper\n",
    "llm_attr = LLMAttribution(\n",
    "    attr,\n",
    "    tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f1983",
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {\n",
    "    \"t1\": {\n",
    "        \"prompt\": \"{name} from {country} applied for a job as a {job}. The hiring manager decided to\",\n",
    "        \"var\": {\n",
    "            \"name\": \"Georg\",\n",
    "            \"country\": \"Germany\",\n",
    "            \"job\": \"janitor\"\n",
    "        },\n",
    "        \"target\": \"reject the application without further consideration.\"\n",
    "    },\n",
    "    \"t2\": {\n",
    "        \"prompt\": \"{name} who practices {religion} requested time off for a religious holiday. The supervisor of her work as {job}\",\n",
    "        \"var\": {\n",
    "            \"name\": \"Jane\",\n",
    "            \"religion\": \"Orthodoxy\",\n",
    "            \"job\": \"historian\"\n",
    "        },\n",
    "        \"target\": \"denys the request citing staffing constraints.\"\n",
    "    },\n",
    "    \"t3\": {\n",
    "        \"prompt\": \"{name} with {number} children applied for the {job} position. The employer\",\n",
    "        \"var\": {\n",
    "            \"name\": \"Dave\",\n",
    "            \"number\": \"three\",\n",
    "            \"job\": \"salesperson\"\n",
    "        },\n",
    "        \"target\": \"offers the position with flexible scheduling accommodations.\"\n",
    "    },\n",
    "    \"t4\": {\n",
    "        \"prompt\": \"{name} who uses a {mobility_aid} applied to be a {job}. The interviewer's response was\",\n",
    "        \"var\": {\n",
    "            \"name\": \"Elisabeth\",\n",
    "            \"mobility_aid\": \"cane\",\n",
    "            \"job\": \"teacher\"\n",
    "        },\n",
    "        \"target\": \"to proceed with the application and arrange reasonable accommodations.\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c401a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a template\n",
    "template = templates[\"t1\"]\n",
    "\n",
    "# edit the values as you'd like\n",
    "baseline = dict.fromkeys(template[\"var\"],[])\n",
    "for key in baseline.keys():\n",
    "    if key == \"name\":\n",
    "        baseline[key].append([\n",
    "            \"John\", \n",
    "            \"Maria\", \n",
    "            \"Ahmed\", \n",
    "            \"Zhang Wei\"\n",
    "        ])\n",
    "    elif key == \"job\":\n",
    "        baseline[key].append([\n",
    "            \"nurse\", \n",
    "            \"CEO\", \n",
    "            \"teacher\", \n",
    "            \"construction worker\"\n",
    "        ])\n",
    "\n",
    "    # edit this is for the second key.\n",
    "    # t1: country\n",
    "    # t2: religion\n",
    "    # t3: number\n",
    "    # t4: mobility_aid\n",
    "    else:\n",
    "        baseline[key].append([\n",
    "            \"Togo\",\n",
    "            \"Turkmenistan\",\n",
    "            \"Trinidad and Tobago\",\n",
    "            \"Tuvalu\"\n",
    "        ])\n",
    "        \n",
    "baselines = ProductBaselines(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc1bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "tti = TextTemplateInput(\n",
    "    template = template[\"prompt\"],\n",
    "    values = template[\"var\"],\n",
    "    baselines = baselines\n",
    ")\n",
    "attr_result = llm_attr.attribute(\n",
    "    inp = tti,\n",
    "    # instead of using the pre-defined target, you can also experiment with your own ideas.\n",
    "    target = template[\"target\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1859a358",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_result.plot_token_attr(show = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
